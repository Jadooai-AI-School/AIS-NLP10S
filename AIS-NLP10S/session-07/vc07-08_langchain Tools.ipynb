{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain Examples Notebook: Tools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ais_utils.Model_from_LC_Ollama import get_chatLLM, get_chatOpenAI, get_chatLLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING IF GPU IS ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Code to Check LLM functioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#chatllm = get_chatOpenAI()\n",
    "llm = get_chatLLM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### --- 2. Tools ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Scholar API Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start by installing semanticscholar api\n",
    "#%pip install --upgrade --quiet  semanticscholar\n",
    "#%pip install --upgrade --quiet  langchainhub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_openai_functions_agent\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions = \"\"\"You are an expert researcher.\"\"\"\n",
    "base_prompt = hub.pull(\"langchain-ai/openai-functions-template\")\n",
    "prompt = base_prompt.partial(instructions=instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.semanticscholar.tool import SemanticScholarQueryRun\n",
    "\n",
    "tools = [SemanticScholarQueryRun()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_openai_functions_agent(llm, tools, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m## Biases in Large Language Models\n",
      "\n",
      "Large language models (LLMs) are trained on massive datasets of text, which can contain biases. These biases can manifest in various ways, including:\n",
      "\n",
      "* **Linguistic biases:** LLMs may learn and perpetuate stereotypes or prejudices from the training data.\n",
      "* **Domain biases:** LLMs may not be able to generalize to new domains, leading to biased outputs.\n",
      "* **Political and social biases:** LLMs may reflect the biases of their training data, leading to biased outputs on sensitive topics.\n",
      "* **Moral biases:** LLMs may be biased towards certain moral values, leading to biased outputs on moral issues.\n",
      "\n",
      "**Mitigating Bias in LLMs**\n",
      "\n",
      "Several techniques have been proposed to mitigate bias in LLMs, including:\n",
      "\n",
      "* **Data cleaning and pre-processing:** Cleaning and pre-processing the training data to remove biases and normalize the data.\n",
      "* **Regularization:** Regularizing the LLM to encourage it to learn a diverse set of weights.\n",
      "* **Prompt engineering:** Using prompts to guide the LLM to generate more diverse and unbiased outputs.\n",
      "* **Bias detection and mitigation:** Identifying and mitigating biases in the LLM architecture or training process.\n",
      "\n",
      "**Research Papers and Techniques**\n",
      "\n",
      "* **Addressing Bias in Language Models: A Survey of the State of the Art** (2022) by Google AI\n",
      "* **Mitigating Bias in Large Language Models** (2022) by Facebook AI\n",
      "* **Detecting and Mitigating Bias in Large Language Models** (2023) by Microsoft Research\n",
      "* **Bias in Large Language Models: A Survey** (2023) by arXiv\n",
      "* **Generating Unbiased Language with Large Language Models** (2023) by Stanford University\n",
      "\n",
      "**Subtasks for Search**\n",
      "\n",
      "* Bias in large language models\n",
      "* Mitigating bias in large language models\n",
      "* Bias in language models\n",
      "* Bias in AI\n",
      "* Responsible AI\n",
      "* Unbiased language generation\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = agent_executor.invoke(\n",
    "    {\n",
    "        \"input\": \"What are some biases in the large language models? How have people tried to mitigate them? \"\n",
    "        \"show me a list of papers and techniques. Based on your findings write new research questions (show in bulleted list)\"\n",
    "        \"to work on. Break down the task into subtasks for search. Use the search tool\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What are some biases in the large language models? How have people tried to mitigate them? show me a list of papers and techniques. Based on your findings write new research questions (show in bulleted list)to work on. Break down the task into subtasks for search. Use the search tool\n",
      "## Biases in Large Language Models\n",
      "\n",
      "Large language models (LLMs) are trained on massive datasets of text, which can contain biases. These biases can manifest in various ways, including:\n",
      "\n",
      "* **Linguistic biases:** LLMs may learn and perpetuate stereotypes or prejudices from the training data.\n",
      "* **Domain biases:** LLMs may not be able to generalize to new domains, leading to biased outputs.\n",
      "* **Political and social biases:** LLMs may reflect the biases of their training data, leading to biased outputs on sensitive topics.\n",
      "* **Moral biases:** LLMs may be biased towards certain moral values, leading to biased outputs on moral issues.\n",
      "\n",
      "**Mitigating Bias in LLMs**\n",
      "\n",
      "Several techniques have been proposed to mitigate bias in LLMs, including:\n",
      "\n",
      "* **Data cleaning and pre-processing:** Cleaning and pre-processing the training data to remove biases and normalize the data.\n",
      "* **Regularization:** Regularizing the LLM to encourage it to learn a diverse set of weights.\n",
      "* **Prompt engineering:** Using prompts to guide the LLM to generate more diverse and unbiased outputs.\n",
      "* **Bias detection and mitigation:** Identifying and mitigating biases in the LLM architecture or training process.\n",
      "\n",
      "**Research Papers and Techniques**\n",
      "\n",
      "* **Addressing Bias in Language Models: A Survey of the State of the Art** (2022) by Google AI\n",
      "* **Mitigating Bias in Large Language Models** (2022) by Facebook AI\n",
      "* **Detecting and Mitigating Bias in Large Language Models** (2023) by Microsoft Research\n",
      "* **Bias in Large Language Models: A Survey** (2023) by arXiv\n",
      "* **Generating Unbiased Language with Large Language Models** (2023) by Stanford University\n",
      "\n",
      "**Subtasks for Search**\n",
      "\n",
      "* Bias in large language models\n",
      "* Mitigating bias in large language models\n",
      "* Bias in language models\n",
      "* Bias in AI\n",
      "* Responsible AI\n",
      "* Unbiased language generation\n"
     ]
    }
   ],
   "source": [
    "print(response['input'])\n",
    "print(response['output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
