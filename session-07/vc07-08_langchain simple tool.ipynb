{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ais_utils.Model_from_LC_Ollama import preload_model, get_chatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preloading model for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model preloader for gemma2:2b...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preload_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING IF GPU IS ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Inference using Langchain LLM \n",
    "(String input, string output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Here's a brief description of William Shakespeare:\\n\\n* **Birth and Death**: Born on April 23, 1564, in Stratford-upon-Avon, England; died on April 23, 1616 (aged 52)\\n* **Occupation**: Playwright, poet, actor, and theatre owner\\n* **Notable Works**:\\n\\t+ Tragedies: Romeo and Juliet, Hamlet, Macbeth, Othello, King Lear\\n\\t+ Comedies: A Midsummer Night's Dream, The Taming of the Shrew, Twelfth Night, As You Like It\\n\\t+ Histories: Henry V, Henry VIII, Richard III\\n* **Innovations**:\\n\\t+ Developed iambic pentameter and blank verse in English poetry\\n\\t+ Introduced complex characters with nuanced motivations\\n\\t+ Explored themes of love, power, mortality, and the human condition\\n* **Legacy**: Considered one of the greatest writers in the English language; his works have been translated into many languages and continue to be widely performed and studied today.\" additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 224, 'prompt_tokens': 23, 'total_tokens': 247}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-40b23779-f4d6-4ef0-bf61-d3f933a05fc2-0' usage_metadata={'input_tokens': 23, 'output_tokens': 224, 'total_tokens': 247}\n"
     ]
    }
   ],
   "source": [
    "llm = get_chatOpenAI(model='llama3.1')\n",
    "\n",
    "resp = llm.invoke('Who is Shakespeare?. Describe briefly in the format of bullet points')\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools) # \n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "resp = llm_with_tools.invoke(query).content\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
