{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ais_utils.Model_from_LC_Ollama import preload_model, get_chatOpenAI\n",
    "from ais_utils.Model_from_LC_Groq import get_chatGroq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preloading model for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model preloader for gemma2:2b...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preload_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING IF GPU IS ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Inference using Langchain LLM \n",
    "(String input, string output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. William Shakespeare: A renowned English playwright, poet, and actor, widely regarded as one of the greatest writers in the English language and world literature.\n",
      "\n",
      "2. Born: Approximately April 26, 1564, in Stratford-upon-Avon, Warwickshire, England.\n",
      "\n",
      "3. Career: Shakespeare's career spanned the late 16th and early 17th centuries, with most of his works being produced between 1589 and 1613.\n",
      "\n",
      "4. Major Works: His most famous works include plays like \"Romeo and Juliet,\" \"Hamlet,\" \"Othello,\" \"King Lear,\" and \"Macbeth.\" He also wrote numerous sonnets and other poems.\n",
      "\n",
      "5. Genre: Shakespeare's works encompass many different genres, including tragedy, comedy, history, and romance.\n",
      "\n",
      "6. Influence: His plays and poetry have had a profound impact on literature, language, and culture worldwide. Many of his phrases and quotes are still in use today.\n",
      "\n",
      "7. Death: Shakespeare died on April 23, 1616, in Stratford-upon-Avon at the age of approximately 52.\n",
      "\n",
      "8. Legacy: Despite dying over four centuries ago, Shakespeare continues to be widely performed and studied around the world. His works are a cornerstone of English literature and have been translated into every major language.\n"
     ]
    }
   ],
   "source": [
    "llm = get_chatOpenAI(model='mistral')\n",
    "\n",
    "resp = llm.invoke('Who is Shakespeare?. Describe briefly in the format of bullet points')\n",
    "print(resp.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TOOL USE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool, Tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools: list[Tool] = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ LLM response: 12 + 7 equals 19.\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the result of adding 12 and 7?\"\n",
    "\n",
    "response = llm.invoke(query)\n",
    "\n",
    "# üõ†Ô∏è Step 4: Handling tool calls if present\n",
    "if response.tool_calls:\n",
    "    for tool_call in response.tool_calls:\n",
    "        tool_name = tool_call[\"name\"]\n",
    "        tool_args = tool_call[\"args\"]\n",
    "        print(f\"üîç LLM wants to call `{tool_name}` with {tool_args}\")\n",
    "\n",
    "        for tool in tools:\n",
    "            if tool.name == tool_name:\n",
    "                result = tool.invoke(tool_args)\n",
    "                print(f\"‚úÖ Tool result: {result}\")\n",
    "else:\n",
    "    print(f\"ü§ñ LLM response: {response.content}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
