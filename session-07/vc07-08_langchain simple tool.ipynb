{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ais_utils.Model_from_LC_Ollama import preload_model, get_chatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preloading model for faster inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running model preloader for gemma:2b...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preload_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECKING IF GPU IS ENABLED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting Inference using Langchain LLM \n",
    "(String input, string output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content=\"Sure. Here's a brief summary of Shakespeare:\\n\\n- **Born:** 1564 in Stratford-upon-Avon, England\\n- **Died:** 1616 in London, England\\n- **Occupation:** Playwright, poet, and statesman\\n- **Major works:**\\n    - Romeo and Juliet\\n    - Hamlet\\n    - Macbeth\\n    - King Lear\\n    - As You Like It\\n- **Key contributions:**\\n    - Shakespeare is widely considered the greatest playwright of all time.\\n    - His plays have had a profound impact on English language and culture.\\n    - He was a master of language and storytelling.\\n    - Shakespeare's work continues to be performed and studied around the world.\" response_metadata={'token_usage': {'completion_tokens': 153, 'prompt_tokens': 39, 'total_tokens': 192}, 'model_name': 'gemma:2b', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None} id='run-061163bb-9355-4f86-a0f8-dc842ddcc63c-0' usage_metadata={'input_tokens': 39, 'output_tokens': 153, 'total_tokens': 192}\n"
     ]
    }
   ],
   "source": [
    "llm = get_chatOpenAI()\n",
    "\n",
    "resp = llm.invoke('Who is Shakespeare?. Describe briefly in the format of bullet points')\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sure, 3 * 12 = 36.\n",
      "\n",
      "3 * 12 is a multiplication problem where we multiply the values 3 and 12. The answer is 36, which is the result of the multiplication.\n"
     ]
    }
   ],
   "source": [
    "llm_with_tools = llm.bind_tools(tools) # \n",
    "\n",
    "query = \"What is 3 * 12?\"\n",
    "\n",
    "resp = llm_with_tools.invoke(query).content\n",
    "print(resp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
